"""
Index embeddings into Qdrant vector database (Hybrid-ready)

This indexer stores:
- Dense vector: sentence-transformers embeddings (named vector: "dense")
- Sparse BM25 vector: generated by Qdrant from text (named sparse vector: "bm25")

IMPORTANT:
- Requires Qdrant version that supports sparse vectors + inference BM25 ("Qdrant/bm25").
- Collection schema must include BOTH:
    vectors_config["dense"]
    sparse_vectors_config["bm25"]
If your collection already exists without these, run --clear and reindex.
"""
from typing import List
import uuid

from qdrant_client import QdrantClient
from qdrant_client import models

from .config import config
from .models import TextChunk


class VectorIndexer:
    """
    Manage Qdrant indexing operations

    Handles connection, collection management, and batch indexing.
    Hybrid-ready: dense + bm25 sparse vectors.
    """

    DENSE_VECTOR_NAME = "dense"
    BM25_VECTOR_NAME = "bm25"
    BM25_MODEL_NAME = "Qdrant/bm25"

    def __init__(self):
        """Initialize Qdrant client and collection"""
        print(f"Connecting to Qdrant at: {config.qdrant_url}")

        self.client = QdrantClient(
            url=config.qdrant_url,
            api_key=config.qdrant_api_key,
        )

        # We lazily ensure the collection on first index call because
        # we want to infer dense vector size from embeddings.
        self._collection_ready = False

        current_count = self._count()
        print(f"✓ Collection '{config.collection_name}' ready")
        print(f"  Current points: {current_count}")

    def _count(self) -> int:
        try:
            res = self.client.count(collection_name=config.collection_name, exact=True)
            return int(res.count)
        except Exception:
            return 0

    def _collection_exists(self) -> bool:
        try:
            existing = [c.name for c in self.client.get_collections().collections]
            return config.collection_name in existing
        except Exception:
            return False

    def _assert_collection_is_hybrid(self):
        """
        If the collection exists, ensure it has the required hybrid schema:
        - named dense vector "dense"
        - sparse vector "bm25"
        """
        info = self.client.get_collection(collection_name=config.collection_name)

        # Dense vectors config
        vectors = getattr(info.config.params, "vectors", None)
        dense_ok = False

        # vectors may be single or named; we require named for hybrid
        # In qdrant-client, named vectors are typically in vectors.vectors (dict-like)
        if hasattr(vectors, "vectors") and isinstance(vectors.vectors, dict):
            dense_ok = self.DENSE_VECTOR_NAME in vectors.vectors
        else:
            dense_ok = False

        # Sparse vectors config
        sparse = getattr(info.config.params, "sparse_vectors", None)
        sparse_ok = False
        if sparse and hasattr(sparse, "sparse_vectors") and isinstance(sparse.sparse_vectors, dict):
            sparse_ok = self.BM25_VECTOR_NAME in sparse.sparse_vectors

        if not dense_ok or not sparse_ok:
            raise RuntimeError(
                f"Collection '{config.collection_name}' exists but is NOT hybrid-configured.\n"
                f"Expected named dense vector '{self.DENSE_VECTOR_NAME}' and sparse vector '{self.BM25_VECTOR_NAME}'.\n\n"
                f"Fix: reindex into a hybrid collection.\n"
                f"Run your index command with --clear (or delete the collection), then reindex.\n"
            )

    def _ensure_collection(self, vector_size: int):
        """
        Ensure hybrid collection exists with:
        - vectors_config: {"dense": VectorParams(size, cosine)}
        - sparse_vectors_config: {"bm25": SparseVectorParams(modifier=IDF)}
        """
        if self._collection_ready:
            return

        if not self._collection_exists():
            # Create fresh hybrid collection
            self.client.create_collection(
                collection_name=config.collection_name,
                vectors_config={
                    self.DENSE_VECTOR_NAME: models.VectorParams(
                        size=vector_size,
                        distance=models.Distance.COSINE,
                    ),
                },
                sparse_vectors_config={
                    self.BM25_VECTOR_NAME: models.SparseVectorParams(
                        modifier=models.Modifier.IDF
                    ),
                },
            )
        else:
            # Collection exists; must match hybrid schema
            self._assert_collection_is_hybrid()

        self._collection_ready = True

    def index_chunks(
        self,
        chunks: List[TextChunk],
        embeddings: List[List[float]],
        batch_size: int = 100,
    ):
        """
        Index chunks with their dense embeddings + bm25 sparse vectors into Qdrant

        Args:
            chunks: List of TextChunk objects
            embeddings: Corresponding dense embedding vectors (same order)
            batch_size: Number of chunks to index per batch
        """
        if len(chunks) != len(embeddings):
            raise ValueError(
                f"Chunk count ({len(chunks)}) must match embedding count ({len(embeddings)})"
            )

        total = len(chunks)
        print(f"\nIndexing {total} chunks into Qdrant (hybrid: dense + bm25)...")

        if total == 0:
            print("✓ Nothing to index")
            return

        # Create collection if needed using the embedding dimension
        vector_size = len(embeddings[0])
        self._ensure_collection(vector_size=vector_size)

        failed_batches = 0
        failed_ranges = []  # (start, end, error_str)

        for i in range(0, total, batch_size):
            end = min(i + batch_size, total)

            try:
                points = []
                for chunk, dense_vec in zip(chunks[i:end], embeddings[i:end]):
                    # deterministic UUID from human stable chunk.id
                    point_id = str(uuid.uuid5(uuid.NAMESPACE_URL, chunk.id))

                    payload = dict(chunk.metadata or {})
                    payload["text"] = chunk.text
                    payload["source_id"] = chunk.id

                    points.append(
                        models.PointStruct(
                            id=point_id,
                            vector={
                                # Dense vector
                                self.DENSE_VECTOR_NAME: dense_vec,
                                # Sparse BM25 vector (Qdrant server-side inference from text)
                                self.BM25_VECTOR_NAME: models.Document(
                                    text=chunk.text,
                                    model=self.BM25_MODEL_NAME,
                                ),
                            },
                            payload=payload,
                        )
                    )

                self.client.upsert(
                    collection_name=config.collection_name,
                    points=points,
                )
                print(f"  Indexed {end}/{total} chunks")
            except Exception as e:
                failed_batches += 1
                failed_ranges.append((i, end, str(e)))
                print(f"  Error indexing batch {i}-{end}: {e}\n")
                # Continue with next batch

        final_count = self._count()
        print(f"\n✓ Indexing complete!")
        print(f"  Total points in collection: {final_count}")

        if failed_batches:
            sample = "\n".join([f"- {a}-{b}: {msg}" for a, b, msg in failed_ranges[:5]])
            raise RuntimeError(
                f"Indexing finished with {failed_batches} failed batch(es).\n"
                f"First failures:\n{sample}"
            )

    def clear_collection(self):
        """
        Clear all points from the collection

        WARNING: This deletes all indexed data!
        """
        print(f"Clearing collection '{config.collection_name}'...")

        try:
            self.client.delete_collection(collection_name=config.collection_name)
        except Exception:
            pass

        self._collection_ready = False
        print("✓ Collection cleared")

    def get_stats(self) -> dict:
        """
        Get statistics about the indexed data

        Returns:
            Dictionary with collection statistics
        """
        count = self._count()
        return {
            "collection_name": config.collection_name,
            "total_documents": count,
            "qdrant_url": config.qdrant_url,
        }
